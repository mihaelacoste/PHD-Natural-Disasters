{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8lxnjaBI1v8wPESzvw3+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihaelacoste/PHD-Natural-Disasters/blob/main/Model_Scene_Composition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIGHmwvuwwQk"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install tensorflow scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "1GnkPg2Bntck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/'\n"
      ],
      "metadata": {
        "id": "nSqy0NGBoyEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/'\n"
      ],
      "metadata": {
        "id": "2JRH3twxo0e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model for Composition elements/scene classification***"
      ],
      "metadata": {
        "id": "8swvPD2rcQHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data directories\n",
        "base_dir = '/content/drive/MyDrive/scene_classification'\n",
        "\n",
        "# Use ImageDataGenerator for data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Create training data generator\n",
        "train_generator = train_datagen.flow_from_directory(base_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpeiOW5qw5Xc",
        "outputId": "9d692bd0-c79a-4aad-f721-141d72b906c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9497 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# Build a simple CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax')) ####add here the number of classes identified at the previous step\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "34HTOydNyTfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=25)"
      ],
      "metadata": {
        "id": "zkTYT9bJyWMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vizualise Training Results***"
      ],
      "metadata": {
        "id": "nre0avI5gO-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n"
      ],
      "metadata": {
        "id": "MT99za6acK9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QkHVe6bwfTe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"/content/model/model_scene_v2.h5\")\n"
      ],
      "metadata": {
        "id": "hAzZv-scyaVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Categorizing images**"
      ],
      "metadata": {
        "id": "JmpTDiN7zZXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    # Load the image from file\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Expand the dimensions to match the input shape of the model\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "def categorize_images(image_folder, output_folder, class_mapping):\n",
        "    for image_file in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, image_file)\n",
        "        img = load_and_preprocess_image(img_path)\n",
        "        img_array = img.reshape(1, 224, 224, 3)\n",
        "        prediction = model.predict(img_array)\n",
        "        category = np.argmax(prediction)\n",
        "\n",
        "        # Use class_mapping to get the actual class label\n",
        "        class_label = class_mapping[category]\n",
        "\n",
        "        # Create output folder if it doesn't exist\n",
        "        category_folder = os.path.join(output_folder, f'category_{class_label}')\n",
        "        os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "        # Move the image to the appropriate folder\n",
        "        shutil.copy(img_path, os.path.join(category_folder, image_file))\n",
        "\n",
        "# Define image and output folders\n",
        "image_folder = \"/content/earthquake\"  # Change this to your  dataset folder\n",
        "output_folder = \"/content/earthquake_composition_categorization\"\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"/content/model_composition_elements.h5\")\n",
        "\n",
        "# Define class mapping based on the order of classes in your training data\n",
        "class_mapping = {0: 'center', 1: 'curved', 2: 'diagonal', 3: 'fill_the_frame', 4: 'golden_ratio', 5: 'horizontal', 6: 'none', 7: 'pattern', 8: 'radial', 9: 'rule_of_thirds', 10: 'symmetric', 11: 'triangle', 12: 'vanishing_point', 13: 'vertical'}\n",
        "\n",
        "# Run categorization\n",
        "categorize_images(image_folder, output_folder, class_mapping)\n"
      ],
      "metadata": {
        "id": "6aj0qtYm0TJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def zip_and_download_folder(folder_path, zip_filename):\n",
        "    shutil.make_archive(zip_filename, 'zip', folder_path)\n",
        "\n",
        "# Specify the path of the folder you want to download\n",
        "output_folder = \"/content/earthquake_composition_categorization\"\n",
        "\n",
        "# Specify the desired name for the zip file\n",
        "zip_filename = \"/content/earthquake_composition_categorization\"\n",
        "\n",
        "# Create a zip file of the folder\n",
        "zip_and_download_folder(output_folder, zip_filename)\n"
      ],
      "metadata": {
        "id": "C1vsD1CR2lwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "id": "2OF463eY2q3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}