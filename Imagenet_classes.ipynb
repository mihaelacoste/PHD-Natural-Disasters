{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihaelacoste/PHD-Natural-Disasters/blob/main/Imagenet_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKATv9Q0LGQM"
      },
      "source": [
        "**ImageNet Classes**\n",
        "\n",
        "Code adapted from the following source:\n",
        "\n",
        "https://cv.gluon.ai/build/examples_classification/demo_imagenet.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@article{gluoncvnlp2020,\n",
        "  author  = {Jian Guo and He He and Tong He and Leonard Lausen and Mu Li and Haibin Lin and Xingjian Shi and Chenguang Wang and Junyuan Xie and Sheng Zha and Aston Zhang and Hang Zhang and Zhi Zhang and Zhongyue Zhang and Shuai Zheng and Yi Zhu},\n",
        "  title   = {GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing},\n",
        "  journal = {Journal of Machine Learning Research},\n",
        "  year    = {2020},\n",
        "  volume  = {21},\n",
        "  number  = {23},\n",
        "  pages   = {1-7},\n",
        "  url     = {http://jmlr.org/papers/v21/19-429.html}\n",
        "}\n",
        "\n",
        "@article{he2018bag,\n",
        "  title={Bag of Tricks for Image Classification with Convolutional Neural Networks},\n",
        "  author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},\n",
        "  journal={arXiv preprint arXiv:1812.01187},\n",
        "  year={2018}\n",
        "}\n",
        "\n",
        "@article{zhang2019bag,\n",
        "  title={Bag of Freebies for Training Object Detection Neural Networks},\n",
        "  author={Zhang, Zhi and He, Tong and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},\n",
        "  journal={arXiv preprint arXiv:1902.04103},\n",
        "  year={2019}\n",
        "}\n",
        "\n",
        "@article{zhang2020resnest,\n",
        "  title={ResNeSt: Split-Attention Networks},\n",
        "  author={Zhang, Hang and Wu, Chongruo and Zhang, Zhongyue and Zhu, Yi and Zhang, Zhi and Lin, Haibin and Sun, Yue and He, Tong and Muller, Jonas and Manmatha, R. and Li, Mu and Smola, Alexander},\n",
        "  journal={arXiv preprint arXiv:2004.08955},\n",
        "  year={2020}\n",
        "}"
      ],
      "metadata": {
        "id": "tuJhjdoYsmkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkVTUJz-EsGx"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQMee8Z_EsGy"
      },
      "source": [
        "# 3. Getting Started with Pre-trained Models on ImageNet\n",
        "\n",
        "`ImageNet <http://www.image-net.org/>`__ is a\n",
        "large labeled dataset of real-world images. It is one of the most\n",
        "widely used dataset in latest computer vision research.\n",
        "\n",
        "|imagenet|\n",
        "\n",
        "In this tutorial, we will show how a pre-trained neural network\n",
        "classifies real world images.\n",
        "\n",
        "For your convenience, we provide a script that loads a pre-trained ``ResNet50_v2`` model,\n",
        "and classifies an input image.\n",
        "For a list of all models we have, please visit `Gluon Model Zoo <../../model_zoo/index.html>`__.\n",
        "\n",
        "## Demo\n",
        "\n",
        "A model trained on ImageNet can classify images into 1000 classes, this makes it\n",
        "much more powerful than the one we showed in the `CIFAR10 demo <demo_cifar10.html>`__.\n",
        "\n",
        ":download:`Download demo_imagenet.py<../../../scripts/classification/imagenet/demo_imagenet.py>`\n",
        "\n",
        "With this script, you can load a pre-trained model and classify any image you have.\n",
        "\n",
        "Let's test with the photo of Mt. Baker again.\n",
        "\n",
        "|image0|\n",
        "\n",
        "::\n",
        "\n",
        "    python demo_imagenet.py --model ResNet50_v2 --input-pic mt_baker.jpg\n",
        "\n",
        "And the model predicts that\n",
        "\n",
        "::\n",
        "\n",
        "    The input picture is classified to be\n",
        "    \t[volcano], with probability 0.558.\n",
        "    \t[alp], with probability 0.398.\n",
        "    \t[valley], with probability 0.018.\n",
        "    \t[lakeside], with probability 0.006.\n",
        "    \t[mountain_tent], with probability 0.006.\n",
        "\n",
        "This time it does a good job. Note that we have listed the top five\n",
        "most probable classes, because with 1000 classes the model may not always rank the\n",
        "correct answer highest. Besides top-1 accuracy, we often also\n",
        "consider top-5 accuracy as a measurement of how well a model can predict.\n",
        "\n",
        "## Next Step\n",
        "\n",
        "If you would like to dive deeper into ``ImageNet`` training,\n",
        "feel free to read the next tutorial on `ImageNet Training <dive_deep_imagenet.html>`__.\n",
        "\n",
        "Or, if you would like to know how to train a powerful model tailored to your own data,\n",
        "please go ahead and read the tutorial on `Transfer learning <transfer_learning_minc.html>`__.\n",
        "\n",
        ".. |imagenet| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/datasets/imagenet_mosaic.jpg\n",
        ".. |image0| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/mt_baker.jpg\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxL4Hc4mFcD8",
        "outputId": "55e3c3b2-bb0e-4af7-a90e-43cd437ac228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2023.11.17)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l799ApLIFjQr",
        "outputId": "92189ec1-e09b-4b7b-bcb6-bc1662ff9fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gluoncv\n",
            "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluoncv) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gluoncv) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gluoncv) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gluoncv) (3.7.1)\n",
            "Collecting portalocker (from gluoncv)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from gluoncv) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gluoncv) (1.11.4)\n",
            "Collecting yacs (from gluoncv)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gluoncv) (1.5.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gluoncv) (6.0.1)\n",
            "Collecting autocfg (from gluoncv)\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from gluoncv) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gluoncv) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->gluoncv) (1.16.0)\n",
            "Installing collected packages: yacs, portalocker, autocfg, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.5.post0 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install gluoncv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QKa6hGmFy_2",
        "outputId": "efad2a47-f642-4a31-84e0-24d8f88afd70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.1.0+cu121\n",
            "Uninstalling torch-2.1.0+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.1.0+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torch-2.1.0+cu121\n",
            "Found existing installation: torchvision 0.16.0+cu121\n",
            "Uninstalling torchvision-0.16.0+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision-0.16.0+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libcudart.7ec1eba6.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libnvjpeg.f00ca762.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libz.76028ad6.so.1\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchvision-0.16.0+cu121\n",
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.1+cu111 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.1+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oEvAIS-cGNsV",
        "outputId": "87c4031c-6767-426d-de87-43f942174c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 torchvision-0.16.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "-DptvlmDHO8i",
        "outputId": "01b49531-34af-41f0-aefe-3b60ce20499c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.2 torchvision-0.16.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall torch torchvision\n",
        "!pip install torch torchvision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NFWMDYhEIH5b",
        "outputId": "ee4fc1c4-40ed-48d9-a9f0-c80c33ab4102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: gluoncv 0.8.0\n",
            "Uninstalling gluoncv-0.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/gluoncv-0.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/gluoncv/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/model_zoo/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/unittests/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled gluoncv-0.8.0\n",
            "Collecting gluoncv==0.10.1\n",
            "  Downloading gluoncv-0.10.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (3.7.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (2.8.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (1.11.4)\n",
            "Collecting tensorboardx (from gluoncv==0.10.1)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decord (from gluoncv==0.10.1)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (4.8.0.76)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (0.1.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (1.5.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (6.0.1)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.10/dist-packages (from gluoncv==0.10.1) (0.0.8)\n",
            "Collecting autogluon.core (from gluoncv==0.10.1)\n",
            "  Downloading autogluon.core-1.0.0-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn<1.5,>=1.3.0 (from autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core->gluoncv==0.10.1) (3.2.1)\n",
            "Collecting pandas (from gluoncv==0.10.1)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2,>=1.10 (from autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading boto3-1.34.25-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==1.0.0 (from autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading autogluon.common-1.0.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core->gluoncv==0.10.1) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core->gluoncv==0.10.1) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->gluoncv==0.10.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gluoncv==0.10.1) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas->gluoncv==0.10.1)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gluoncv==0.10.1) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv==0.10.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv==0.10.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv==0.10.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gluoncv==0.10.1) (2023.11.17)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx->gluoncv==0.10.1) (3.20.3)\n",
            "Collecting botocore<1.35.0,>=1.34.25 (from boto3<2,>=1.10->autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading botocore-1.34.25-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core->gluoncv==0.10.1)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->gluoncv==0.10.1) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5,>=1.3.0->autogluon.core->gluoncv==0.10.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5,>=1.3.0->autogluon.core->gluoncv==0.10.1) (3.2.0)\n",
            "Installing collected packages: tzdata, tensorboardx, jmespath, decord, scikit-learn, pandas, botocore, s3transfer, boto3, autogluon.common, autogluon.core, gluoncv\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.19.1 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autogluon.common-1.0.0 autogluon.core-1.0.0 boto3-1.34.25 botocore-1.34.25 decord-0.6.0 gluoncv-0.10.1 jmespath-1.0.1 pandas-2.1.4 s3transfer-0.10.0 scikit-learn-1.4.0 tensorboardx-2.6.2.2 tzdata-2023.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall gluoncv\n",
        "!pip install gluoncv==0.10.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Bp7IOOFBqs",
        "outputId": "51de169e-aa5a-467b-ba28-90a9a9e729b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet50_v2-ecdde353.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v2-ecdde353.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "92863KB [00:02, 43578.48KB/s]                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input picture is classified to be\n",
            "\t[lakeside], with probability 0.389.\n",
            "\t[boathouse], with probability 0.364.\n",
            "\t[dam], with probability 0.068.\n",
            "\t[palace], with probability 0.028.\n",
            "\t[castle], with probability 0.023.\n"
          ]
        }
      ],
      "source": [
        "from mxnet import nd, image\n",
        "import gluoncv as gcv\n",
        "from gluoncv.data import ImageNet1kAttr\n",
        "from gluoncv.data.transforms.presets.imagenet import transform_eval\n",
        "from gluoncv.model_zoo import get_model\n",
        "\n",
        "# Set parameters directly in the code\n",
        "model_name = 'ResNet50_v2'  # Change to the desired model\n",
        "saved_params = ''  # Path to the saved model parameters, leave empty for pretrained\n",
        "input_pic = '/content/ecfdc2b5b9e0cec50baa4299d177f8f1.jpg'  # Path to the input picture\n",
        "\n",
        "# Load Model\n",
        "pretrained = True if saved_params == '' else False\n",
        "net = get_model(model_name, pretrained=pretrained)\n",
        "\n",
        "if not pretrained:\n",
        "    net.load_parameters(saved_params)\n",
        "    attrib = ImageNet1kAttr()\n",
        "    classes = attrib.classes\n",
        "else:\n",
        "    classes = net.classes\n",
        "\n",
        "# Load Images\n",
        "img = image.imread(input_pic)\n",
        "\n",
        "# Transform\n",
        "img = transform_eval(img)\n",
        "pred = net(img)\n",
        "\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input picture is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.' % (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQSllNe1JHu7",
        "outputId": "aaade599-acd7-4cee-e6a5-49ab805601ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results for 1c25dba18b01a3ec501e10267468ae7b.jpg:\n",
            "\t[wallaby], with probability 0.995.\n",
            "\t[hare], with probability 0.003.\n",
            "\t[red wolf], with probability 0.000.\n",
            "\t[coyote], with probability 0.000.\n",
            "\t[ibex], with probability 0.000.\n",
            "\n",
            "Results for 0eccd7c7c4ac0513cb78a5b03a79ce36.jpg:\n",
            "\t[church], with probability 0.509.\n",
            "\t[palace], with probability 0.248.\n",
            "\t[castle], with probability 0.065.\n",
            "\t[analog clock], with probability 0.046.\n",
            "\t[dome], with probability 0.034.\n",
            "\n",
            "Results for 1a477934fdbcbdf9a32afaf17b8693bd.jpg:\n",
            "\t[wallaby], with probability 0.977.\n",
            "\t[hare], with probability 0.011.\n",
            "\t[wood rabbit], with probability 0.010.\n",
            "\t[Madagascar cat], with probability 0.000.\n",
            "\t[lynx], with probability 0.000.\n",
            "\n",
            "Results for 0f304b27dd55771289b1f5a7273cae69.jpg:\n",
            "\t[vase], with probability 0.459.\n",
            "\t[goblet], with probability 0.145.\n",
            "\t[pitcher], with probability 0.059.\n",
            "\t[table lamp], with probability 0.046.\n",
            "\t[lampshade], with probability 0.041.\n",
            "\n",
            "Results for 0dab382ed5728fc392d777cba4923909.jpg:\n",
            "\t[toy terrier], with probability 0.191.\n",
            "\t[Chihuahua], with probability 0.101.\n",
            "\t[Border terrier], with probability 0.091.\n",
            "\t[Appenzeller], with probability 0.080.\n",
            "\t[Norwich terrier], with probability 0.057.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Specify the folder containing images\n",
        "image_folder = '/content/aus'\n",
        "\n",
        "# Iterate over all image files in the folder\n",
        "for image_file in os.listdir(image_folder):\n",
        "    # Check if the file is an image (you can add more file type checks if needed)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "        # Construct the full path to the image file\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "        # Load Images\n",
        "        img = image.imread(image_path)\n",
        "\n",
        "        # Transform\n",
        "        img = transform_eval(img)\n",
        "        pred = net(img)\n",
        "\n",
        "        topK = 5\n",
        "        ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "\n",
        "        print(f'\\nResults for {image_file}:')\n",
        "        for i in range(topK):\n",
        "            print(f'\\t[{classes[ind[i].asscalar()]}], with probability {nd.softmax(pred)[0][ind[i]].asscalar():.3f}.')\n",
        "\n",
        "# After processing all images, you can print overall statistics or do further analysis\n",
        "# For example, you can accumulate probabilities for each class and print the top classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZLWeovmfKI4b",
        "outputId": "d7a16205-04ee-4bae-df22-f35455e3a362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Classes based on Average Probabilities:\n",
            "\t[koala], Average Probability: 0.050.\n",
            "\t[comic book], Average Probability: 0.041.\n",
            "\t[web site], Average Probability: 0.033.\n",
            "\t[book jacket], Average Probability: 0.033.\n",
            "\t[volcano], Average Probability: 0.020.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the folder containing images\n",
        "image_folder = '/content/australia'\n",
        "\n",
        "# Initialize a dictionary to store cumulative probabilities for each class\n",
        "cumulative_probs = {class_name: 0.0 for class_name in classes}\n",
        "\n",
        "# Initialize a list to store individual image results\n",
        "results_list = []\n",
        "\n",
        "# Iterate over all image files in the folder\n",
        "for image_file in os.listdir(image_folder):\n",
        "    # Check if the file is an image (you can add more file type checks if needed)\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "        # Construct the full path to the image file\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "\n",
        "        # Load Images\n",
        "        img = image.imread(image_path)\n",
        "\n",
        "        # Transform\n",
        "        img = transform_eval(img)\n",
        "        pred = net(img)\n",
        "\n",
        "        topK = 10\n",
        "        ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "\n",
        "        # Collect results for each image\n",
        "        image_results = {'Image': image_file}\n",
        "        for i in range(topK):\n",
        "            class_name = classes[ind[i].asscalar()]\n",
        "            probability = nd.softmax(pred)[0][ind[i]].asscalar()\n",
        "            image_results[f'Class_{i+1}'] = class_name\n",
        "            image_results[f'Probability_{i+1}'] = probability\n",
        "\n",
        "            # Accumulate probabilities for each class\n",
        "            cumulative_probs[class_name] += probability\n",
        "\n",
        "        # Append individual image results to the list\n",
        "        results_list.append(image_results)\n",
        "\n",
        "# Create a DataFrame from the list of individual image results\n",
        "df = pd.DataFrame(results_list)\n",
        "\n",
        "# Save individual image results to an Excel file\n",
        "df.to_excel('australia_imagenet_results.xlsx', index=False)\n",
        "\n",
        "# Calculate average probabilities for each class\n",
        "average_probs = {class_name: cumulative_prob / len(results_list) for class_name, cumulative_prob in cumulative_probs.items()}\n",
        "\n",
        "# Print the top classes based on average probabilities\n",
        "top_classes = sorted(average_probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "print('\\nTop Classes based on Average Probabilities:')\n",
        "for class_name, avg_prob in top_classes:\n",
        "    print(f'\\t[{class_name}], Average Probability: {avg_prob:.3f}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEazCJ0ysmKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identify pairs of co-occurent classes for VosViewer**"
      ],
      "metadata": {
        "id": "H8G5J9eg0p5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.xlsx' with the path to your Excel file\n",
        "file_path = 'Italia.xlsx'\n",
        "df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "lnRlyijy0sEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pairs\n",
        "df['class_pair'] = df.apply(lambda row: tuple(sorted([row['Class_1'], row['Class_2']])), axis=1)\n",
        "\n",
        "# Count the frequency of each unique pair\n",
        "class_pair_freq = df.groupby('class_pair').agg(frequency=('id', 'nunique')).reset_index()\n",
        "\n",
        "# Split the class_pair tuple into separate columns\n",
        "class_pair_freq[['Class_1', 'Class_2']] = pd.DataFrame(class_pair_freq['class_pair'].tolist(), index=class_pair_freq.index)\n",
        "class_pair_freq.drop(columns=['class_pair'], inplace=True)\n"
      ],
      "metadata": {
        "id": "Bn2X-NcY0uJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'output_file.csv' with your desired output file path\n",
        "output_file = 'Italia.csv'\n",
        "class_pair_freq.to_csv(output_file, index=False)\n"
      ],
      "metadata": {
        "id": "vqyj3ki70wqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageNet wide categories"
      ],
      "metadata": {
        "id": "2MQk4QK98IX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the WordNet corpus\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "E2OF7_hB8r2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use WordNet as intended\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Example usage: Finding broader categories for 'dog'\n",
        "dog_synsets = wn.synsets('book_jacket', pos=wn.NOUN)\n",
        "\n",
        "for synset in dog_synsets:\n",
        "    # Navigate up the hypernym paths and explore or pick a broader category\n",
        "    hypernym_paths = synset.hypernym_paths()\n",
        "    for path in hypernym_paths:\n",
        "        # Print out the hypernym path for illustration\n",
        "        print(\" -> \".join(synset.name().split('.')[0] for synset in path))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8VLLT238NK0",
        "outputId": "ac4c5369-ea52-42d6-924b-5414a663b541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entity -> physical_entity -> object -> whole -> artifact -> covering -> wrapping -> jacket -> book_jacket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual wide categories code"
      ],
      "metadata": {
        "id": "8my-FQYJ-1Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk openpyxl\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXDTyArA-3DK",
        "outputId": "bb59b9f5-0ed9-4e3a-ee67-c0ced00d11b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ALL** **CATEGORIES**"
      ],
      "metadata": {
        "id": "35hpm6PMNIon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_categories(term):\n",
        "    # Attempt to find the term directly in WordNet\n",
        "    synsets = wn.synsets(term, pos=wn.NOUN)\n",
        "\n",
        "    # If the term is compound and not found, try with underscores\n",
        "    if not synsets and ' ' in term:\n",
        "        synsets = wn.synsets(term.replace(' ', '_'), pos=wn.NOUN)\n",
        "\n",
        "    if not synsets:  # If no synset is found for the term\n",
        "        return []\n",
        "\n",
        "    # Select the first synset for the term\n",
        "    synset = synsets[0]\n",
        "    # Select the first hypernym path and collect all categories in this path\n",
        "    hypernym_path = synset.hypernym_paths()[0]\n",
        "\n",
        "    # Extract the category names from the synsets in the hypernym path\n",
        "    categories = [hypernym.name().split('.')[0] for hypernym in hypernym_path]\n",
        "\n",
        "    return categories\n"
      ],
      "metadata": {
        "id": "j1BVnrF0NH9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('Italy.xlsx')\n",
        "max_categories = 0\n",
        "for index, row in df.iterrows():\n",
        "    class1 = row['Class_1'].lower()  # Lowercase for consistency with WordNet\n",
        "    categories = find_all_categories(class1)\n",
        "    if categories:\n",
        "        max_categories = max(max_categories, len(categories))\n"
      ],
      "metadata": {
        "id": "YPP8RcWpNjBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add columns dynamically based on the maximum number of categories\n",
        "for i in range(max_categories):\n",
        "    df[f'Category_{i+1}'] = None  # Column names will be Category_1, Category_2, ...\n",
        "\n",
        "# Populate the categories\n",
        "for index, row in df.iterrows():\n",
        "    class1 = row['Class_1'].lower()\n",
        "    categories = find_all_categories(class1)\n",
        "    for i, category in enumerate(categories):\n",
        "        df.at[index, f'Category_{i+1}'] = category\n"
      ],
      "metadata": {
        "id": "1bkUToHNNl-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('updated_Italy_all.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "hpdRezoVNpQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}